{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../configs/user_config.yaml\") as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "\n",
    "load_dotenv(\"../configs/environment_variables.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge base Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"ytl_plr_sample\"\n",
    "DATA_PATH = \"../../data/ytl_plr_sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.generative.index import build_index\n",
    "from azure.ai.resources.client import AIClient\n",
    "from azure.ai.resources.operations._index_data_source import (\n",
    "    ACSOutputConfig,\n",
    "    LocalSource,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from azure.search.documents.models import RawVectorQuery\n",
    "from openai import AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cogsearch_index(\n",
    "    index_name: str,\n",
    "    path_to_data: str,\n",
    "    chunk_size: int,\n",
    "    chunk_overlap: int,\n",
    "    data_source_url: str = None,\n",
    "):\n",
    "    # Set up environment variables for cog search SDK\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_TARGET\"] = os.environ.get(\n",
    "        \"AZURE_AI_SEARCH_ENDPOINT\", \"\"\n",
    "    )\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_KEY\"] = os.environ.get(\"AZURE_AI_SEARCH_KEY\", \"\")\n",
    "\n",
    "    client = AIClient.from_config(DefaultAzureCredential())\n",
    "\n",
    "    default_aoai_connection = client.get_default_aoai_connection()\n",
    "    default_aoai_connection.set_current_environment()\n",
    "\n",
    "    default_acs_connection = client.connections.get(\n",
    "        os.environ.get(\"AZURE_COGNITIVE_SEARCH_CONNECTION_NAME\", \"\")\n",
    "    )\n",
    "    default_acs_connection.set_current_environment()\n",
    "\n",
    "    # Use the same index name when registering the index in AI Studio\n",
    "    index = build_index(\n",
    "        output_index_name=index_name,\n",
    "        vector_store=\"azure_cognitive_search\",\n",
    "        embeddings_model=f\"azure_open_ai://deployment/{os.environ.get('AZURE_OPENAI_EMBEDDING_DEPLOYMENT')}/model/{os.environ.get('AZURE_OPENAI_EMBEDDING_MODEL')}\",\n",
    "        data_source_url=data_source_url,\n",
    "        index_input_config=LocalSource(input_data=path_to_data),\n",
    "        acs_config=ACSOutputConfig(\n",
    "            acs_index_name=index_name,\n",
    "        ),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "\n",
    "    # register the index so that it shows up in the project\n",
    "    cloud_index = client.indexes.create_or_update(index)\n",
    "\n",
    "    print(f\"Created index '{cloud_index.name}'\")\n",
    "    print(f\"Local Path: {index.path}\")\n",
    "    print(f\"Cloud Path: {cloud_index.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AIClient: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "2024-03-22 14:39:00,772 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar to /tmp/tika-server.jar.\n",
      "2024-03-22 14:39:07,498 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar.md5 to /tmp/tika-server.jar.md5.\n",
      "2024-03-22 14:39:08,883 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
      "[DocumentChunksIterator::filter_extensions] Filtered 0 files out of 6\n",
      "[DocumentChunksIterator::crack_documents] Total time to load files: 0.0002727508544921875\n",
      "{\n",
      "  \".txt\": 5.0,\n",
      "  \".md\": 0.0,\n",
      "  \".html\": 0.0,\n",
      "  \".htm\": 0.0,\n",
      "  \".py\": 0.0,\n",
      "  \".pdf\": 0.0,\n",
      "  \".ppt\": 0.0,\n",
      "  \".pptx\": 0.0,\n",
      "  \".doc\": 0.0,\n",
      "  \".docx\": 1.0,\n",
      "  \".xls\": 0.0,\n",
      "  \".xlsx\": 0.0\n",
      "}\n",
      "[DocumentChunksIterator::split_documents] Total time to split 6 documents into 24 chunks: 0.5905618667602539\n",
      "Processing document: pangkorlautresort_com_villas_html.txt0\n",
      "Processing document: pangkorlautresort_com_villas_html.txt1\n",
      "Processing document: pangkorlautresort_com_villas_html.txt2\n",
      "Processing document: pangkorlautresort_com_villas_html.txt3\n",
      "Processing document: pangkorlautresort_com_villas_html.txt4\n",
      "Processing document: pangkorlautresort_com_the-estates_html.txt0\n",
      "Processing document: pangkorlautresort_com_the-estates_html.txt1\n",
      "Processing document: pangkorlautresort_com_the-estates_html.txt2\n",
      "Processing document: pangkorlautresort_com_the-estates_html.txt3\n",
      "Processing document: pangkorlautresort_com_the-estates_html.txt4\n",
      "Processing document: pangkorlautresort_com_the-estates_html.txt5\n",
      "Processing document: pangkorlautresort_com_the-estates_html.txt6\n",
      "Processing document: pangkorlautresort_com_weddings_html.txt0\n",
      "Processing document: pangkorlautresort_com_weddings_html.txt1\n",
      "Processing document: pangkorlautresort_com_weddings_html.txt2\n",
      "Processing document: pangkorlautresort_com_weddings_html.txt3\n",
      "Processing document: pangkorlautresort_com_weddings_html.txt4\n",
      "Processing document: pangkorlautresort_com_special-offers_html.txt0\n",
      "Processing document: pangkorlautresort_com_special-offers_html.txt1\n",
      "Processing document: pangkorlautresort_com_special-offers_html.txt2\n",
      "Processing document: pangkorlautresort_com_events_html.txt0\n",
      "Processing document: pangkorlautresort_com_events_html.txt1\n",
      "Processing document: pangkorlautresort_com_events_html.txt2\n",
      "Processing document: dummy_promotion_march_april.docx0\n",
      "Documents to embed: 24\n",
      "Documents reused: 0\n",
      "Attempt 0 to embed 16 documents.\n",
      "Attempt 0 to embed 8 documents.\n",
      "Updating ACS index\n",
      "Using Index fields: {\n",
      "  \"content\": \"content\",\n",
      "  \"url\": \"url\",\n",
      "  \"filename\": \"filepath\",\n",
      "  \"title\": \"title\",\n",
      "  \"metadata\": \"meta_json_string\",\n",
      "  \"embedding\": \"contentVector\"\n",
      "}\n",
      "Ensuring search index ytl_plr_sample exists\n",
      "Creating ytl_plr_sample search index\n",
      "Created ytl_plr_sample search index\n",
      "0 documents from sources marked for deletion, adding individual documents marked for deletion\n",
      "Total 0 documents marked for deletion\n",
      "Documents include embeddings: True\n",
      "Processing documents from: pangkorlautresort_com_villas_html\n",
      "Processed source: pangkorlautresort_com_villas_html\n",
      "Total Documents: 5\n",
      "Skipped: 0\n",
      "Added: 5\n",
      "Processing documents from: pangkorlautresort_com_the-estates_html\n",
      "Processed source: pangkorlautresort_com_the-estates_html\n",
      "Total Documents: 7\n",
      "Skipped: 0\n",
      "Added: 7\n",
      "Processing documents from: pangkorlautresort_com_weddings_html\n",
      "Processed source: pangkorlautresort_com_weddings_html\n",
      "Total Documents: 5\n",
      "Skipped: 0\n",
      "Added: 5\n",
      "Processing documents from: pangkorlautresort_com_special-offers_html\n",
      "Processed source: pangkorlautresort_com_special-offers_html\n",
      "Total Documents: 3\n",
      "Skipped: 0\n",
      "Added: 3\n",
      "Processing documents from: pangkorlautresort_com_events_html\n",
      "Processed source: pangkorlautresort_com_events_html\n",
      "Total Documents: 3\n",
      "Skipped: 0\n",
      "Added: 3\n",
      "Processing documents from: dummy_promotion_march_april\n",
      "Sending 24 documents to ACS\n",
      "Uploaded 24 documents to ACS in 7.0718 seconds, 0 failed\n",
      "Uploaded documents\n",
      "Built index from 24 documents and 24 chunks, took 7.0871 seconds\n",
      "Built index\n",
      "Writing MLIndex yaml\n",
      "\u001b[32mUploading ytl_plr_sample-mlindex (0.0 MBs): 100%|██████████| 833/833 [00:00<00:00, 5903.72it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index 'ytl_plr_sample'\n",
      "Local Path: /home/abin/Projects/openai-hackathon/hacks/codes/notebooks/ytl_plr_sample-mlindex\n",
      "Cloud Path: azureml://subscriptions/5f388ce8-ce4d-4fca-aff5-d39d62b5cb8e/resourcegroups/scb_openaihack_rg/workspaces/abinjoseph_v2/datastores/workspaceblobstore/paths/LocalUpload/b69a310f399891ddc853cc53a6ca16b6/ytl_plr_sample-mlindex/\n"
     ]
    }
   ],
   "source": [
    "build_cogsearch_index(\n",
    "    index_name=INDEX_NAME,\n",
    "    path_to_data=DATA_PATH,\n",
    "    chunk_size=model_config[\"rag\"][\"chunk_size\"],\n",
    "    chunk_overlap=model_config[\"rag\"][\"chunk_overlap\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with Documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "import nest_asyncio\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_documents(\n",
    "    question: str,\n",
    "    index_name: str,\n",
    "    num_docs=5,\n",
    ") -> str:\n",
    "    #  retrieve documents relevant to the user's question from Cognitive Search\n",
    "    search_client = SearchClient(\n",
    "        endpoint=os.environ.get(\"AZURE_AI_SEARCH_ENDPOINT\", \"\"),\n",
    "        credential=AzureKeyCredential(os.environ.get(\"AZURE_AI_SEARCH_KEY\", \"\")),\n",
    "        index_name=index_name,\n",
    "    )\n",
    "\n",
    "    async with AsyncAzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"\"),\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"\"),\n",
    "    ) as aclient:\n",
    "\n",
    "        # generate a vector embedding of the user's question\n",
    "        embedding = await aclient.embeddings.create(\n",
    "            input=question, model=os.environ.get(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "        )\n",
    "        embedding_to_query = embedding.data[0].embedding\n",
    "\n",
    "    context = \"\"\n",
    "    contexts = []\n",
    "    async with search_client:\n",
    "        # use the vector embedding to do a vector search on the index\n",
    "        vector_query = RawVectorQuery(\n",
    "            vector=embedding_to_query, k=num_docs, fields=\"contentVector\"\n",
    "        )\n",
    "        results = await search_client.search(\n",
    "            search_text=\"\", vector_queries=[vector_query], select=[\"id\", \"content\"]\n",
    "        )\n",
    "\n",
    "        async for result in results:\n",
    "            context += f\"\\n>>> {result['content']}\"\n",
    "            contexts.append(result[\"content\"])\n",
    "\n",
    "    return context, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_message(user_prompt: str, system_role: str) -> List[dict]:\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_role},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "def chat_completion(\n",
    "    question: str,\n",
    "    system_role: str,\n",
    "    user_prompt: str,\n",
    "    index_name: str,\n",
    "    num_docs: int = 5,\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int = 800,\n",
    "):\n",
    "    # get search documents for the last user message in the conversation\n",
    "    context, contexts = asyncio.run(\n",
    "        get_documents(\n",
    "            question=question,\n",
    "            index_name=index_name,\n",
    "            num_docs=num_docs,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # TODO: Add context to user message\n",
    "    user_prompt = user_prompt.format(question=question, context=context)\n",
    "    message = build_message(user_prompt=user_prompt, system_role=system_role)\n",
    "\n",
    "    with AzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"\"),\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"\"),\n",
    "    ) as client:\n",
    "\n",
    "        # call Azure OpenAI with the system prompt and user's question\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT\"),\n",
    "            messages=message,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "\n",
    "    response = {\n",
    "        \"choices\": [\n",
    "            {\n",
    "                \"index\": 0,\n",
    "                \"message\": {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": chat_completion.choices[0].message.content,\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # add context in the returned response\n",
    "    context_dict = {\n",
    "        \"context\": context,\n",
    "        \"contexts\": contexts,\n",
    "        \"num_docs\": num_docs,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "    response[\"choices\"][0][\"context\"] = context_dict\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_documents(question: str):\n",
    "    result = chat_completion(\n",
    "        question=question,\n",
    "        system_role=model_config[\"prompt\"][\"system_role\"],\n",
    "        user_prompt=model_config[\"prompt\"][\"user_prompt\"]\n",
    "        + \"\\n\\nQuestion:'{question}' \\n\\nContext: '{context}'\",\n",
    "        index_name=INDEX_NAME,\n",
    "        num_docs=model_config[\"rag\"][\"num_docs\"],\n",
    "        temperature=model_config[\"model\"][\"temperature\"],\n",
    "        max_tokens=model_config[\"model\"][\"max_tokens\"],\n",
    "    )\n",
    "    print(result[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answering on the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amenities available in the villas include comfortable bedding, a writing desk, a powered safe, a large open ensuite bathroom with an oversized bathtub and two vanity units, an outdoor verandah or balcony with sun loungers, complimentary WiFi, tea and coffee making facilities, a minibar, a ceiling fan, in-room climate control, and a selection of international newspapers.\n"
     ]
    }
   ],
   "source": [
    "chat_with_documents(\n",
    "    question=\"what are the amenities available in villas?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd codes/src/rag_ai_studio\n",
    "streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureaistudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
